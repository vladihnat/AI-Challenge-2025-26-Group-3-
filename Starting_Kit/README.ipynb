{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09168ba-aee6-499d-920f-9a579fb2e51f",
   "metadata": {},
   "source": [
    "# Pollinator Detection – Starting Kit\n",
    "---\n",
    "\n",
    "Description of your challenge and instructions for challenge participants :\n",
    "\n",
    "This notebook is the starting kit for the Pollinator Detection challenge. Its goal is to guide participants through the first steps of the project by demonstrating how to load the data, explore it, visualize examples, and build initial models using the provided tools.\n",
    "\n",
    "The dataset used in this challenge consists of .h5 files, where each file contains a sequence of images and is associated with a binary label indicating the presence (1) or absence (0) of a pollinator. Throughout this notebook, each sequence is treated as a single data sample.\n",
    "\n",
    "When running this notebook, the required data will be automatically downloaded if it is not already available locally.\n",
    "\n",
    "This notebook is organized to progressively introduce the main components of the challenge:\n",
    "- Data loading: how to access the dataset and configure memory usage or sampling size.\n",
    "- Data exploration and visualization: how to inspect class distribution, visualize image sequences, and gain intuition about the data.\n",
    "- Baseline modeling: simple examples illustrating how one might begin training and evaluating a model.\n",
    "- Evaluation: an introduction to some appropriate metrics.\n",
    "\n",
    "This notebook does not aim to provide a final or optimal solution. Instead, it serves as a reference implementation and learning tool to help participants understand the challenge and confidently begin developing their own approaches.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cd7134-67aa-4aab-b287-26df611b5755",
   "metadata": {},
   "source": [
    "`COLAB` determines whether this notebook is running on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470321f4-c578-4ca8-a7eb-7eb89932ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a41e1-ae51-4dda-83d2-ba725991c793",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # clone github repo\n",
    "    !git clone --depth 1 https://github.com/vladihnat/AI-Challenge-2025-26-Group-3-.git\n",
    "    # move to the starting kit folder\n",
    "    %cd AI-Challenge-2025-26-Group-3-/Starting_Kit/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e0f37b-38ce-4471-bd28-175323314b9b",
   "metadata": {},
   "source": [
    "# 0 - Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1284d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# List of required libraries\n",
    "libraries = [\n",
    "    \"xgboost\",\n",
    "    \"scikit-image\", \n",
    "    \"scikit-learn\",\n",
    "    \"imblearn\",\n",
    "    \"h5py\",\n",
    "    \"gdown\",\n",
    "    \"tqdm\",\n",
    "    \"joblib\",\n",
    "    \"seaborn\",\n",
    "    \"matplotlib\"\n",
    "]\n",
    "\n",
    "# You can use this cell to install any missing libraries on your environment\n",
    "print(\"[*] Checking libraries...\")\n",
    "for lib in libraries:\n",
    "    # We use pip to install if import fails\n",
    "    # 'scikit-image' is installed via scikit-image but imported via skimage\n",
    "    # 'imblearn' is installed via imbalanced-learn\n",
    "    install_name = lib\n",
    "    if lib == \"scikit-image\": install_name = \"scikit-image\"\n",
    "    if lib == \"imblearn\": install_name = \"imbalanced-learn\"\n",
    "    \n",
    "    !{sys.executable} -m pip install -q {install_name}\n",
    "\n",
    "print(\"[✔] All libraries are ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a956880-e2b9-4868-8446-ad66302d9211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "import h5py\n",
    "import gdown\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from xgboost import XGBClassifier\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, cross_val_predict\n",
    "from sklearn.metrics import f1_score, confusion_matrix, balanced_accuracy_score, ConfusionMatrixDisplay, make_scorer\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ebf1d0",
   "metadata": {},
   "source": [
    "# 1 - Data\n",
    "\n",
    "## Description\n",
    "\n",
    "This class provides an automated pipeline for handling the challenge datasets. It automatically downloads the train and test set if they are not already present. It then load a fraction of the data, using a stratified slicing to keep the dataset intrisic proportion of both classes in the train and test set. The stratified slicing ensures that even when loading a small fraction of the data for fast prototyping, the rare \"Visitor\" class ratio (approx. 2.7%) is perfectly preserved. It offers a flexible memory management toggle, allowing users to choose between high-speed sequential RAM loading or memory-efficient direct-disk access.\n",
    "\n",
    "## How to use it\n",
    "\n",
    "Initialize: Create an instance by specifying your local data directory.\n",
    "\n",
    "Load: Call load_data() with two key parameters:\n",
    "\n",
    "sample_fraction: Set between 0.0 and 1.0 (e.g., 0.1 to load 10% for quick testing).\n",
    "\n",
    "load_to_memory: Set to True for maximum speed (requires ~3GB RAM) or False if working on a machine with limited memory\n",
    "\n",
    "Split: Call split_data() to get a training set and a test set. DO NOT USE X_hidden ! It's the test set of the challenge, given here so you can make your predictions, but you do not have labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121fdc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, data_dir=\"data\"):\n",
    "        self.data_dir = data_dir\n",
    "        self.X_train, self.y_train = None, None\n",
    "        self.X_test, self.y_test = None, None\n",
    "        self.X_hidden = None # to make predictions on hidden test set\n",
    "        self.X_train_full = None # to train the final model on full data\n",
    "        self.y_train_full = None # to train the final model on full data\n",
    "        \n",
    "    def download_data(self):\n",
    "        \"\"\"Downloads files from Google Drive if not present.\"\"\"\n",
    "        if not os.path.exists(self.data_dir):\n",
    "            os.makedirs(self.data_dir)\n",
    "\n",
    "        files = {\n",
    "            \"train_data.h5\": \"16o5myKPxvl8YcHejz_FQPEmZXn7Z9pA6\",\n",
    "            \"train_labels.npy\": \"1mgvUrig6zwG84Thv0O63RiSc4JUUUUtQ\",\n",
    "            \"test_data.h5\": \"1oN1fmmUutH-a5oGCdoYP4vuJWZUkEEFX\",\n",
    "        }\n",
    "\n",
    "        for name, file_id in files.items():\n",
    "            path = os.path.join(self.data_dir, name)\n",
    "            if not os.path.exists(path) or os.path.getsize(path) < 1000:\n",
    "                print(f\"[*] Downloading {name}...\")\n",
    "                url = f'https://drive.google.com/uc?id={file_id}'\n",
    "                gdown.download(url, path, quiet=False)\n",
    "            else:\n",
    "                print(f\"[OK] {name} is ready.\")\n",
    "\n",
    "    def load_data(self, sample_fraction=1.0, load_to_memory=True):\n",
    "        \"\"\"\n",
    "        Loads the data. If sample_fraction < 1.0, it performs a stratified \n",
    "        sampling to keep only X% of the dataset.\n",
    "        \"\"\"\n",
    "        self.download_data()\n",
    "        print(f\"[*] Loading data (fraction={sample_fraction*100}%)...\")\n",
    "\n",
    "        # Load TRAINING labels\n",
    "        y_full = np.load(os.path.join(self.data_dir, \"train_labels.npy\"), allow_pickle=True)\n",
    "        \n",
    "        idx_tr = None\n",
    "        if sample_fraction < 1.0:\n",
    "            from sklearn.model_selection import train_test_split\n",
    "            idx_tr, _ = train_test_split(\n",
    "                np.arange(len(y_full)), \n",
    "                train_size=sample_fraction, \n",
    "                stratify=y_full, \n",
    "                random_state=42\n",
    "            )\n",
    "            idx_tr = sorted(idx_tr)\n",
    "            self.y_train_full = y_full[idx_tr]\n",
    "        else:\n",
    "            self.y_train_full = y_full\n",
    "\n",
    "        with h5py.File(os.path.join(self.data_dir, \"train_data.h5\"), \"r\") as f:\n",
    "            print(f\"[*] Loading training images...\")\n",
    "            if idx_tr is not None:\n",
    "                self.X_train_full = f[\"images\"][idx_tr]\n",
    "            else:\n",
    "                self.X_train_full = f[\"images\"][:]\n",
    "\n",
    "        # Load Hidden TEST set \n",
    "        with h5py.File(os.path.join(self.data_dir, \"test_data.h5\"), \"r\") as f:\n",
    "            print(f\"[*] Loading hidden test images...\")\n",
    "            self.X_hidden = f[\"images\"][:]\n",
    "\n",
    "        print(f\"[✔] Loaded {len(y)} train samples and {self.X_hidden.shape[0]} test samples.\")\n",
    "    \n",
    "    def split_data(self, test_size=0.25):\n",
    "        \"\"\"\n",
    "        Splits the loaded training data into a local training set and a validation set.\n",
    "        This ensures we don't touch the final 'test_data.h5' during training.\n",
    "        \"\"\"\n",
    "        print(f\"[*] Splitting data (Validation size = {test_size*100}%)...\")\n",
    "        \n",
    "        # train_test_split with 'stratify'.\n",
    "        # it ensures class 0 and class 1 proportions are identical in both sets.        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X_train_full, self.y_train_full, \n",
    "            test_size=test_size, \n",
    "            stratify=self.y_train_full, \n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Sanity Check\n",
    "        train_insects = np.sum(self.y_train == 1)\n",
    "        test_insects = np.sum(self.y_test == 1)\n",
    "        \n",
    "        print(f\"[✔] Split Complete:\")\n",
    "        print(f\"    - Train: {len(self.y_train)} samples ({train_insects} insects, {100*train_insects/len(self.y_train):.2f}%)\")\n",
    "        print(f\"    - Valid: {len(self.y_test)} samples ({test_insects} insects, {100*test_insects/len(self.y_test):.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f1a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_manager = Data(data_dir=\"data\")\n",
    "\n",
    "# sample_fraction=0.1 for quick testing (load 10% of data)\n",
    "# Loading with load_to_memory=True requires ~3-4GB of free RAM (faster)\n",
    "# Loading with load_to_memory=False is slower but more memory efficient\n",
    "X, y = data_manager.load_data(sample_fraction=1.0, load_to_memory=True)\n",
    "\n",
    "# About 2 minutes to download the data\n",
    "# Less than 2 minutes to load the full data into memory with load_to_memory=True\n",
    "\n",
    "# Split to create train and test set\n",
    "data_manager.split_data(X, y, test_size=0.25) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6fa112",
   "metadata": {},
   "source": [
    "# 2 - Visualization\n",
    "\n",
    "This section allows for an exploratory analysis of the dataset to understand the class distribution and visually inspect the samples.\n",
    "\n",
    "## What we have implemented:\n",
    "\n",
    "### Class Distribution Analysis: \n",
    "A bar chart to visualize the significant imbalance between the \"No Visitor\" (0) and \"Visitor\" (1) classes. This highlights why standard accuracy is misleading and why we prioritize Balanced Accuracy and F1-Score later in this notebook.\n",
    "\n",
    "### Sample Inspection: \n",
    "A grid display of random images from each class.\n",
    "\n",
    "### Dimensionality Reduction (PCA):\n",
    "A 2D projection of the raw pixels. By balancing the classes for this specific visualization, we can see if \"Visitor\" images cluster together or if they are indistinguishable from \"No Visitor\" images in the raw pixel space.\n",
    "\n",
    "We then performed a PCA on HOG features (see section 3 for explanations and justifications about HOG), to try and find if this method separates the classes better. \n",
    "\n",
    "Then, we performed a PCA on HOG features with a grayfilter applied, to see if grayfilters would neutralize the difficulty of colors.\n",
    "\n",
    "Finally, we tried a multiscale HOG (grayscale on PCA) and performed a PCA on it.\n",
    "\n",
    "Theses steps aim to help us identify which feature extraction looks the best for classifying our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1245b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualize:\n",
    "    def __init__(self, data_manager, n_per_class=500, n_imgs=3):\n",
    "        \"\"\"\n",
    "        Initialize the class with the data manager and optimal HOG parameters.\n",
    "        \"\"\"\n",
    "        self.data = data_manager\n",
    "\n",
    "        # HOG parameters (optimized)\n",
    "        # Actual hyperparameters are for 10% of the dataset, the ones for 100% are commented out\n",
    "        self.best_h_orient = 12 # 9 \n",
    "        self.best_h_pix = (16, 16) # (8, 8)\n",
    "        self.best_h_block = (1, 1)\n",
    "        self.best_h_transform_sqrt = False\n",
    "        # orientation, pixels_per_cell, cells_per_block, transform_sqrt\n",
    "        self.s1_config = (12, (16, 16), (1, 1), False)\n",
    "        self.s2_config = (9, (8, 8), (1, 1), False)\n",
    "\n",
    "        self.n_per_class = n_per_class\n",
    "        self.n_imgs = n_imgs\n",
    "        np.random.seed(42)\n",
    "\n",
    "    # --- Parallel Helpers (Internal) ---\n",
    "    def _process_single(self, img, grayscale):\n",
    "        \"\"\"Helper for parallel single-scale extraction.\"\"\"\n",
    "        img_proc = rgb2gray(img) if grayscale else img\n",
    "        c_axis = None if grayscale else -1\n",
    "        return hog(img_proc, orientations=self.best_h_orient, \n",
    "                   pixels_per_cell=self.best_h_pix, cells_per_block=self.best_h_block, \n",
    "                   transform_sqrt=self.best_h_transform_sqrt, channel_axis=c_axis)\n",
    "\n",
    "    def _process_multi(self, img, grayscale):\n",
    "        \"\"\"Helper for parallel multi-scale extraction.\"\"\"\n",
    "        img_proc = rgb2gray(img) if grayscale else img\n",
    "        c_axis = None if grayscale else -1\n",
    "        # Scale 1: global\n",
    "        h1 = hog(img_proc, orientations=self.s1_config[0], pixels_per_cell=self.s1_config[1],\n",
    "                 cells_per_block=self.s1_config[2], transform_sqrt=self.s1_config[3], channel_axis=c_axis)\n",
    "        # Scale 2: local\n",
    "        h2 = hog(img_proc, orientations=self.s2_config[0], pixels_per_cell=self.s2_config[1],\n",
    "                 cells_per_block=self.s2_config[2], transform_sqrt=self.s2_config[3], channel_axis=c_axis)\n",
    "        return np.concatenate([h1, h2])\n",
    "\n",
    "    # --- Extraction Methods ---\n",
    "    def extract_hog(self, grayscale=False):\n",
    "        \"\"\"\n",
    "        Extract HOG features from images using parallel processing.\n",
    "        \"\"\"\n",
    "        desc = \"Extracting HOG (Grayscale)\" if grayscale else \"Extracting HOG (RGB)\"\n",
    "        features_list = Parallel(n_jobs=-1)(\n",
    "            delayed(self._process_single)(img, grayscale) for img in tqdm(self.data.X_train, desc=desc)\n",
    "        )\n",
    "        return np.array(features_list)\n",
    "    \n",
    "    def extract_hog_multiscale(self, grayscale=False):\n",
    "        \"\"\"\n",
    "        Multi-scale HOG using parallel processing.\n",
    "        \"\"\"\n",
    "        desc = \"Extracting Multi-scale HOG (Grayscale)\" if grayscale else \"Extracting Multi-scale HOG (RGB)\"\n",
    "        features_list = Parallel(n_jobs=-1)(\n",
    "            delayed(self._process_multi)(img, grayscale) for img in tqdm(self.data.X_train, desc=desc)\n",
    "        )\n",
    "        return np.array(features_list)\n",
    "\n",
    "    # --- Plotting Methods ---\n",
    "    def plot_class_distribution(self):\n",
    "        \"\"\"Displays the class distribution in the training dataset.\"\"\"\n",
    "        print(\"[*] Plotting class distribution...\")\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        names = [\"Visitor\" if l == 1 else \"No Visitor\" for l in self.data.y_train]\n",
    "        sns.countplot(x=names, palette=\"magma\", hue=names, legend=False)\n",
    "        plt.title(\"Class Distribution (0: No Visitor vs 1: Visitor)\")\n",
    "        plt.xlabel(\"Category\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.show()\n",
    "\n",
    "    def show_images(self):\n",
    "        \"\"\"Displays random sample images for each class.\"\"\"\n",
    "        print(f\"[*] Displaying {self.n_imgs} random samples per class...\")\n",
    "        fig, axes = plt.subplots(2, self.n_imgs, figsize=(15, 8))\n",
    "        \n",
    "        for class_id in [0, 1]:\n",
    "            idx_list = np.where(self.data.y_train == class_id)[0]\n",
    "            selected_idx = np.random.choice(idx_list, self.n_imgs, replace=False)\n",
    "            \n",
    "            for i, idx in enumerate(selected_idx):\n",
    "                ax = axes[class_id, i]\n",
    "                ax.imshow(self.data.X_train[idx])\n",
    "                label_str = \"Visitor\" if class_id == 1 else \"No Visitor\"\n",
    "                ax.set_title(f\"Class {class_id}: {label_str}\")\n",
    "                ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def _apply_pca_plot(self, X_features, title):\n",
    "        \"\"\"Internal method to compute and display PCA.\"\"\"\n",
    "        idx_0 = np.where(self.data.y_train == 0)[0]\n",
    "        idx_1 = np.where(self.data.y_train == 1)[0]\n",
    "        \n",
    "        selected_0 = np.random.choice(idx_0, min(self.n_per_class, len(idx_0)), replace=False)\n",
    "        selected_1 = np.random.choice(idx_1, min(self.n_per_class, len(idx_1)), replace=False)\n",
    "        indices = np.concatenate([selected_0, selected_1])\n",
    "        \n",
    "        X_subset = X_features[indices]\n",
    "        y_subset = self.data.y_train[indices]\n",
    "                \n",
    "        pca = PCA(n_components=2, random_state=42)\n",
    "        X_pca = pca.fit_transform(X_subset)\n",
    "        \n",
    "        plt.figure(figsize=(10, 7))\n",
    "        for label_val, color, label_name in [(0, 'steelblue', 'No Visitor'), (1, 'orange', 'Visitor')]:\n",
    "            mask = y_subset == label_val\n",
    "            plt.scatter(X_pca[mask, 0], X_pca[mask, 1], \n",
    "                        c=color, label=label_name, alpha=0.6, edgecolors='w', s=60)\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"PC 1\")\n",
    "        plt.ylabel(\"PC 2\")\n",
    "        plt.grid(True, linestyle='--', alpha=0.4)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_pca_comparison(self):\n",
    "        \"\"\"Displays PCA comparison on various feature extraction methods.\"\"\"\n",
    "        # 1. Raw Pixels\n",
    "        print(f\"[*] Computing PCA on Raw Pixels...\")\n",
    "        X_pixels = self.data.X_train.reshape(len(self.data.X_train), -1)\n",
    "        self._apply_pca_plot(X_pixels, \"PCA: Raw Pixels\")\n",
    "\n",
    "        # 2. HOG RGB\n",
    "        X_hog = self.extract_hog(grayscale=False)\n",
    "        self._apply_pca_plot(X_hog, \"PCA: HOG (RGB)\")\n",
    "\n",
    "        # 3. HOG Grayscale\n",
    "        X_hog_gray = self.extract_hog(grayscale=True)\n",
    "        self._apply_pca_plot(X_hog_gray, \"PCA: HOG (Grayscale)\")\n",
    "\n",
    "        # 4. Multi-scale HOG RGB\n",
    "        X_hog_multi = self.extract_hog_multiscale(grayscale=False)\n",
    "        self._apply_pca_plot(X_hog_multi, \"PCA: Multi-scale HOG (RGB)\")\n",
    "\n",
    "        # 5. Multi-scale HOG Grayscale\n",
    "        X_hog_multi_gray = self.extract_hog_multiscale(grayscale=True)\n",
    "        self._apply_pca_plot(X_hog_multi_gray, \"PCA: Multi-scale HOG (Grayscale)\")\n",
    "\n",
    "    def run_all(self):\n",
    "        \"\"\"Run all visualization methods in sequence.\"\"\"\n",
    "        self.plot_class_distribution()\n",
    "        self.show_images()      \n",
    "        self.plot_pca_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44035d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = Visualize(data_manager, n_per_class=500, n_imgs=3)\n",
    "viz.run_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16da1232",
   "metadata": {},
   "source": [
    "We notice a high imbalance between classes, with over 97% \"No Visitors\" and less than 3% \"Visitors\". This problem will have to be adressed later in the training and scoring.\n",
    "\n",
    "The PCA on raw pixels shows that both classes overlap, probably due to the background of the images (the flowers) being predominant. We see a few cluster but they do not appear as class clusters. Therefore raw pixels seem like a really bad way to perform our classification.\n",
    "\n",
    "The PCA on HOG shows more clusters and a bit of separation between both classes. Many clusters for class Visitor is normal as they represent different insects, but some No Visitor images also have their own cluster. We could pin this on angles and colors of the images. Still, HOG looks better than raw pixels for a classification task as both classes seems more defined and we can notice some separation.\n",
    "\n",
    "The PCA on the grayfilter applied to HOG did not reveal any better separation than HOG alone and did not show better preliminary results. We can notice two well defined clusters, but most points from class 1 overlap with the class 0, more than without the gray filter, making it harder for classification.\n",
    "\n",
    "The PCA with the multiscale HOG showed promising results with more elongation along the axis, and some clusters being well defined. Though during training we couldn't find any improvement, and it made the model bigger (the features vector is bigger) so less resources efficient. The grayfilter on the multiscale didn't change much things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4a6c33",
   "metadata": {},
   "source": [
    "# 3 - Training\n",
    "In this section, we transition from raw image data to a structured machine learning pipeline. We implement an XGBoost Classifier coupled with Histogram of Oriented Gradients (HOG) to establish a robust and high-performance baseline for pollinator detection.\n",
    "\n",
    "## Feature Extraction: Why HOG?\n",
    "Instead of feeding raw pixels directly into the model, which is computationally expensive and sensitive to lighting changes, we use HOG (Histogram of Oriented Gradients). HOG is often considered a spiritual ancestor to Convolutional Neural Networks (CNNs). While a CNN learns its own filters to detect edges and shapes, HOG uses fixed mathematical gradients to describe the \"structure\" and \"shape\" of objects.\n",
    "\n",
    "Unlike deep learning models that require GPUs, HOG is extremely light. It captures the essential geometry of an insect (wings, legs, body orientation) while ignoring redundant color noise. It remains fast enough to run on a standard laptop. We tried a single scale HOG and a multiscale HOG, which is more greedy but could help capture more details.\n",
    " \n",
    "## The Model: Why XGBoost?\n",
    "After initial testing with Random Forest, we opted for XGBoost (Extreme Gradient Boosting) to handle the complexity of our dataset Unlike Random Forest, where trees are built independently, XGBoost builds trees sequentially. Each new tree is specifically designed to correct the errors made by the previous ones. This makes it significantly more effective at capturing subtle patterns in the HOG features that a Random Forest might miss.\n",
    "\n",
    "With a \"Visitor\" class of only ~2.7%, standard models often struggle. We use the scale_pos_weight parameter, which mathematically penalizes the model more heavily for misclassifying an insect than for misclassifying a flower. This \"aggressive\" focus on the minority class is key to breaking the 0.5 balanced accuracy ceiling (where the model only predicts the class 0).\n",
    "\n",
    "XGBoost includes $L1$ and $L2$ regularization, which helps prevent the model from \"memorizing\" the training images (overfitting), ensuring it performs better on new, unseen videos. By using tree_method='hist', XGBoost bins the HOG features into discrete bins, making the training process faster and less memory-intensive than traditional tree-based methods, even with large feature vectors.\n",
    "\n",
    "## What We Are Doing\n",
    "We have built a dynamic pipeline that allows for Hyperparameter Optimization on two levels: \n",
    "\n",
    "HOG Tuning: Finding the right \"resolution\" (pixels per cell) and orientation to ensure the model can distinguish an insect from a petal.\n",
    "\n",
    "XGBoost Tuning: Optimizing the hyperparameters to find the perfect balance between detecting every insect and avoiding false alarms. We trained it by phases by training first the hyperparameters related to the structure, then the ones related to the learning, then to the regularization and finally by the sampling/stochatiscity.\n",
    "\n",
    "We also compared two oversampling methods (random oversampling and SMOTE) versus increasing scale_pos_weight. SMOTE takes two points from the minority class and creates a new one at the center of the line between these points. This method can be good when classes are organized in clusters, here we don't expect much from it as our classes are not well separated. Random Oversampler just duplicates some points, which is expected to work better than SMOTE.\n",
    "\n",
    "Finally, we trained the prediction threshold. Our model gives for each example the probability of being an insect. By default, the model predicts \"Insects\" if the probability is > 0.5. We shift this threshold between 0.1 and 0.6, because the model could tend to be very sure that there's in no insect, but could hesitate to predict insect to avoid being penalized, therefore lowering this threshold is promising.\n",
    "\n",
    "This approach provides a lightweight baseline. It respects the constraints of a standard computer while delivering a performance benchmark that competes with much heavier architectures.\n",
    "\n",
    "## Running time\n",
    "The running time to train one model with 10% of the dataset is about 30 seconds. The total training is about 3 minutes (cross validation with 5 splits + final mod).\n",
    "\n",
    "HOG features extraction is about 20 seconds for train images and 10 seconds for test images.\n",
    "\n",
    "The running time to train one model with 100% of the dataset is about 10 minutes.\n",
    "\n",
    "HOG features extraction is about 4 minutes for train images and 1 minute for test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d94565",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(self, data_manager, grayscale=False, multiscale=False, oversampling='random', ratio=0.1):\n",
    "        \"\"\"\n",
    "        Initializes pipeline and triggers HOG extraction immediately.\n",
    "        \"\"\"\n",
    "        # Actual hyperparameters are for 10% of the dataset, the ones for 100% are commented out\n",
    "        self.data = data_manager\n",
    "        self.X_train_features = None \n",
    "        self.y_train = None\n",
    "\n",
    "        # Parameters for XGBoost\n",
    "        self.model = XGBClassifier(\n",
    "            n_estimators=250,      \n",
    "            max_depth=5,           \n",
    "            learning_rate=0.03,    \n",
    "            subsample=0.8,         \n",
    "            colsample_bytree=0.8,  \n",
    "            scale_pos_weight=10,\n",
    "            min_child_weight=5,\n",
    "            gamma=0.5,  \n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=1.0,\n",
    "            tree_method='hist',\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            enable_categorical=False,\n",
    "            max_delta_step=1,\n",
    "        )\n",
    "\n",
    "        # Parameters for HOG\n",
    "        self.best_h_orient = 12 # 9\n",
    "        self.best_h_pix = (16, 16) # (8, 8)\n",
    "        self.best_h_block = (1, 1)\n",
    "        self.best_h_transform_sqrt = False\n",
    "        self.grayscale = grayscale\n",
    "        self.multiscale = multiscale\n",
    "        # orientation, pixels_per_cell, cells_per_block, transform_sqrt\n",
    "        self.s1_config = (12, (16, 16), (1, 1), False)\n",
    "        self.s2_config = (9, (8, 8), (1, 1), False)\n",
    "\n",
    "        # Threshold for classification\n",
    "        self.threshold = 0.5\n",
    "\n",
    "        # Parameters for oversampling\n",
    "        self.oversampling = oversampling\n",
    "        self.ratio = ratio\n",
    "        \n",
    "        self.prepare_data()\n",
    "\n",
    "    # --- Parallel Helpers ---\n",
    "    def _process_single(self, img):\n",
    "        \"\"\"Helper for parallel single-scale extraction.\"\"\"\n",
    "        img_proc = rgb2gray(img) if self.grayscale else img\n",
    "        c_axis = None if self.grayscale else -1\n",
    "        return hog(img_proc, orientations=self.best_h_orient, \n",
    "                   pixels_per_cell=self.best_h_pix, cells_per_block=self.best_h_block, \n",
    "                   transform_sqrt=self.best_h_transform_sqrt, channel_axis=c_axis)\n",
    "\n",
    "    def _process_multi(self, img):\n",
    "        \"\"\"Helper for parallel multi-scale extraction.\"\"\"\n",
    "        img_proc = rgb2gray(img) if self.grayscale else img\n",
    "        c_axis = None if self.grayscale else -1\n",
    "        h1 = hog(img_proc, orientations=self.s1_config[0], pixels_per_cell=self.s1_config[1],\n",
    "                    cells_per_block=self.s1_config[2], transform_sqrt=self.s1_config[3], channel_axis=c_axis)\n",
    "        h2 = hog(img_proc, orientations=self.s2_config[0], pixels_per_cell=self.s2_config[1],\n",
    "                 cells_per_block=self.s2_config[2], transform_sqrt=self.s2_config[3], channel_axis=c_axis)\n",
    "        return np.concatenate([h1, h2])\n",
    "\n",
    "    def extract_hog(self):\n",
    "        \"\"\"\n",
    "        Extracts HOG features from images with progress bar.\n",
    "        \"\"\"\n",
    "        # Parallel extraction across all CPU cores\n",
    "        features_list = Parallel(n_jobs=-1)(\n",
    "            delayed(self._process_single)(img) for img in tqdm(self.data.X_train, desc=\"Extracting HOG Features\")\n",
    "        )\n",
    "        return np.array(features_list)\n",
    "\n",
    "    def extract_hog_multiscale(self):\n",
    "        \"\"\"\n",
    "        Multi-scale HOG with controlled complexity.\n",
    "        Designed to keep computation reasonable while\n",
    "        capturing fine insect-level details.\n",
    "        \"\"\"\n",
    "        # Parallel extraction across all CPU cores\n",
    "        features_list = Parallel(n_jobs=-1)(\n",
    "            delayed(self._process_multi)(img) for img in tqdm(self.data.X_train, desc=\"Extracting Multi-scale HOG\")\n",
    "        )\n",
    "        return np.array(features_list)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "        Prepares training data by extracting HOG features.\n",
    "        \"\"\"\n",
    "        print(f\"[*] Extracting HOG features from {len(self.data.X_train)} images...\")\n",
    "        if self.multiscale:\n",
    "            self.X_train_features = self.extract_hog_multiscale()\n",
    "        else:\n",
    "            self.X_train_features = self.extract_hog()\n",
    "        self.y_train = self.data.y_train\n",
    "        \n",
    "        print(f\"[OK] Ready to train on {self.X_train_features.shape[0]} samples.\")\n",
    "        print(f\"[*] Feature vector size: {self.X_train_features.shape[1]}\")\n",
    "\n",
    "    def tune_parameters(self, phase=1):\n",
    "        \"\"\"\n",
    "        Runs Grid Search to exhaustively find the best hyperparameters.\n",
    "        \"\"\"\n",
    "        if self.X_train_features is None:\n",
    "            self.prepare_data(grayscale=self.grayscale, multiscale=self.multiscale)\n",
    "\n",
    "        # Mapping phases to specific parameter grids\n",
    "        grids = {\n",
    "            1: {\n",
    "                'max_depth': [3, 5, 7],\n",
    "                'min_child_weight': [15, 30, 50],\n",
    "                # 'gamma': [0, 0.5, 1],\n",
    "                'scale_pos_weight': [3, 5, 10, 20],\n",
    "                'max_delta_step': [0, 1]\n",
    "            },\n",
    "            2: {\n",
    "                'learning_rate': [0.005, 0.01, 0.03],\n",
    "                'n_estimators': [500, 1000, 1500]\n",
    "            },\n",
    "            3: {\n",
    "                'reg_alpha':  [0, 0.5, 1],\n",
    "                'reg_lambda': [1, 5, 10, 20]\n",
    "            },\n",
    "            4: {\n",
    "                'subsample': [0.5, 0.6, 0.8],\n",
    "                'colsample_bytree': [0.5, 0.6, 0.8]\n",
    "            }\n",
    "        }\n",
    "\n",
    "        if phase not in grids:\n",
    "            print(f\"[!] Phase {phase} not recognized. Available phases: {list(grids.keys())}\")\n",
    "            return\n",
    "        param_grid = grids.get(phase, grids[1])\n",
    "\n",
    "        print(f\"[*] Starting GridSearchCV (Phase {phase})...\")\n",
    "        search = GridSearchCV(\n",
    "            self.model, \n",
    "            param_grid=param_grid,\n",
    "            cv=3,\n",
    "            scoring='f1',\n",
    "            n_jobs=1,\n",
    "            verbose=2\n",
    "        )\n",
    "\n",
    "        search.fit(self.X_train_features, self.y_train)\n",
    "        self.model = search.best_estimator_\n",
    "        \n",
    "        print(f\"[✔] Best Parameters found: {search.best_params_}\")\n",
    "        print(f\"[✔] Best CV F1 Score: {search.best_score_:.4f}\")\n",
    "\n",
    "    def tune_hog_settings(self):\n",
    "        \"\"\"\n",
    "        Finds the best HOG parameters for Single-scale mode.\n",
    "        \"\"\"\n",
    "        hog_grid = [\n",
    "            {'pix': (8, 8),   'orient': 6, 'block': (1, 1)},\n",
    "            {'pix': (8, 8),   'orient': 9,  'block': (1, 1)},\n",
    "            # {'pix': (8, 8),   'orient': 12, 'block': (1, 1)},\n",
    "            {'pix': (12, 12),   'orient': 6, 'block': (1, 1)},\n",
    "            {'pix': (12, 12),   'orient': 9, 'block': (1, 1)},\n",
    "            # {'pix': (16, 16), 'orient': 6, 'block': (1, 1)},\n",
    "            # {'pix': (16, 16), 'orient': 9,  'block': (1, 1)},\n",
    "            # {'pix': (16, 16), 'orient': 12, 'block': (1, 1)},\n",
    "            # {'pix': (32, 32), 'orient': 6, 'block': (1, 1)}\n",
    "            # {'pix': (32, 32), 'orient': 9,  'block': (1, 1)},\n",
    "            # {'pix': (32, 32), 'orient': 12, 'block': (1, 1)},   \n",
    "        ]\n",
    "        \n",
    "        best_score = (0, 0)\n",
    "        best_params = None\n",
    "        \n",
    "        print(f\"[*] Tuning HOG (Grayscale={self.grayscale})...\")\n",
    "        for config in hog_grid:\n",
    "            print(f\"--- Testing: {config} ---\")\n",
    "            self.best_h_pix = config['pix']\n",
    "            self.best_h_orient = config['orient']\n",
    "            self.best_h_block = config['block']\n",
    "            \n",
    "            X_feats = self.extract_hog()\n",
    "            \n",
    "            cv_results = cross_validate(self.model, X_feats, self.data.y_train, \n",
    "                                        cv=3, scoring=['balanced_accuracy', 'f1'], n_jobs=1)\n",
    "            \n",
    "            mean_f1 = cv_results['test_f1'].mean()\n",
    "            mean_ba = cv_results['test_balanced_accuracy'].mean()\n",
    "            std_f1 = cv_results['test_f1'].std()\n",
    "            std_ba = cv_results['test_balanced_accuracy'].std()\n",
    "            print(f\"Result (Balanced Acc): {mean_ba:.4f} ± {std_ba:.4f}\")\n",
    "            print(f\"Result (F1): {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "            \n",
    "            if mean_f1 > best_score[0]:\n",
    "                best_score = (mean_f1, mean_ba)\n",
    "                best_std = (std_f1, std_ba)\n",
    "                best_params = config\n",
    "\n",
    "        self.best_h_orient = best_params['orient']\n",
    "        self.best_h_pix = best_params['pix']\n",
    "        self.best_h_block = best_params['block']\n",
    "        print(f\"\\n[✔] Best Single-Scale: {best_params} (Score F1: {best_score[0]:.4f} ± {best_std[0]:.4f}) (Balanced Acc: {best_score[1]:.4f} ± {best_std[1]:.4f})\")\n",
    "        self.prepare_data(grayscale=self.grayscale, multiscale=False)\n",
    "\n",
    "    def tune_multiscale_settings(self):\n",
    "        \"\"\"\n",
    "        Tunes multi-scale HOG parameters.\n",
    "        \"\"\"\n",
    "        multi_grid = [\n",
    "            {'s1': (12, (16, 16)), 's2': (9, (8, 8))},  \n",
    "            {'s1': (9, (16, 16)), 's2': (6, (8, 8))},  \n",
    "            {'s1': (12, (32, 32)),  's2': (9, (16, 16))},  \n",
    "            {'s1': (9, (32, 32)), 's2': (6, (16, 16))},\n",
    "        ]\n",
    "        \n",
    "        best_score = (0, 0)\n",
    "        best_config = None\n",
    "        \n",
    "        print(f\"[*] Tuning Multiscale (Grayscale={self.grayscale})...\")\n",
    "        for config in multi_grid:\n",
    "            print(f\"--- Testing Combo: S1={config['s1']} + S2={config['s2']} ---\")\n",
    "            X_feats = self.extract_hog_multiscale()\n",
    "            \n",
    "            cv_results = cross_validate(self.model, X_feats, self.data.y_train, \n",
    "                                        cv=3, scoring=['balanced_accuracy', 'f1'], n_jobs=1)\n",
    "            \n",
    "            mean_f1 = cv_results['test_f1'].mean()\n",
    "            mean_ba = cv_results['test_balanced_accuracy'].mean()\n",
    "            std_f1 = cv_results['test_f1'].std()\n",
    "            std_ba = cv_results['test_balanced_accuracy'].std()\n",
    "            print(f\"Result (Balanced Acc): {mean_ba:.4f} ± {std_ba:.4f}\")\n",
    "            print(f\"Result (F1): {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "            \n",
    "            if mean_f1 > best_score[0]:\n",
    "                best_score = (mean_f1, mean_ba)\n",
    "                best_std = (std_f1, std_ba)\n",
    "                best_config = config\n",
    "\n",
    "        self.s1_config = best_config['s1']\n",
    "        self.s2_config = best_config['s2']\n",
    "        print(f\"\\n[✔] Best Multi-Scale: {best_config} (Score F1: {best_score[0]:.4f} ± {best_std[0]:.4f}) (Balanced Acc: {best_score[1]:.4f} ± {best_std[1]:.4f})\")\n",
    "        self.prepare_data(grayscale=self.grayscale, multiscale=True)\n",
    "\n",
    "    def tune_threshold(self, thresholds=None):\n",
    "        \"\"\"\n",
    "        Finds the optimal probability threshold using cross-validation to maximize F1-Score.\n",
    "        \"\"\"\n",
    "        if thresholds is None:\n",
    "            thresholds = np.arange(0.1, 0.6, 0.05)\n",
    "            \n",
    "        if self.X_train_features is None:\n",
    "            self.prepare_data(grayscale=self.grayscale, multiscale=self.multiscale)\n",
    "\n",
    "        print(f\"[*] Tuning threshold via 3-fold Cross-Validation...\")\n",
    "        \n",
    "        # Get probabilities via cross-validation\n",
    "        # This allows obtaining a probability for each training set sample\n",
    "        # as if it were in a test set (out-of-fold).\n",
    "        y_probs = cross_val_predict(\n",
    "            self.model, \n",
    "            self.X_train_features, \n",
    "            self.y_train, \n",
    "            cv=3, \n",
    "            method='predict_proba', \n",
    "            n_jobs=1\n",
    "        )[:, 1]\n",
    "\n",
    "        best_f1 = -1\n",
    "        best_ba = -1\n",
    "        best_threshold = 0.5\n",
    "        results = []\n",
    "\n",
    "        # Test each threshold\n",
    "        for thr in thresholds:\n",
    "            y_pred = (y_probs >= thr).astype(int)\n",
    "            f1 = f1_score(self.y_train, y_pred)\n",
    "            ba = balanced_accuracy_score(self.y_train, y_pred)\n",
    "            \n",
    "            results.append((thr, f1, ba))\n",
    "            \n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_ba = ba\n",
    "                best_threshold = thr\n",
    "\n",
    "        print(f\"\\n{'Threshold':<12} | {'F1-Score':<10} | {'Balanced Acc':<12}\")\n",
    "        print(\"-\" * 40)\n",
    "        for thr, f1, ba in results:\n",
    "            mark = \" <--\" if thr == best_threshold else \"\"\n",
    "            print(f\"{thr:<12.3f} | {f1:<10.4f} | {ba:<12.4f}{mark}\")\n",
    "\n",
    "        print(f\"\\n[✔] Best Threshold found: {best_threshold:.3f} (F1: {best_f1:.4f}) (Balanced Acc: {best_ba:.4f})\")\n",
    "        self.threshold = best_threshold\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the final model. \n",
    "        Performs a 5-fold Cross-Validation using the optimized threshold \n",
    "        to report realistic F1 and Balanced Accuracy scores before final fitting.\n",
    "        \"\"\"\n",
    "        if self.X_train_features is None:\n",
    "            self.prepare_data(grayscale=self.grayscale, multiscale=self.multiscale)\n",
    "\n",
    "        X_final, y_final = self.X_train_features, self.y_train\n",
    "\n",
    "        # Handle class imbalance with oversampling if requested\n",
    "        if self.oversampling is not None:\n",
    "            print(f\"[*] Applying {self.oversampling} oversampling to reach ratio {self.ratio}...\")\n",
    "            current_ratio = np.sum(self.y_train == 1) / np.sum(self.y_train == 0)\n",
    "            strategy = self.ratio / (1 - self.ratio)\n",
    "            if strategy > current_ratio:\n",
    "                if self.oversampling.lower() == 'smote':\n",
    "                    sampler = SMOTE(sampling_strategy=strategy, random_state=42)\n",
    "                elif self.oversampling.lower() == 'random':\n",
    "                    sampler = RandomOverSampler(sampling_strategy=strategy, random_state=42)\n",
    "                else:\n",
    "                    print(f\"[!] Unknown oversampling method: {self.oversampling}. Skipping oversampling.\")\n",
    "                    sampler = None\n",
    "                if sampler is not None:\n",
    "                    X_final, y_final = sampler.fit_resample(X_final, y_final)\n",
    "\n",
    "        # We define helper functions that apply our optimized threshold to the probabilities\n",
    "        def f1_at_threshold(y_true, y_probs):\n",
    "            # y_probs will be the probabilities for the positive class (class 1)\n",
    "            y_pred = (y_probs >= self.threshold).astype(int)\n",
    "            return f1_score(y_true, y_pred)\n",
    "\n",
    "        def ba_at_threshold(y_true, y_probs):\n",
    "            y_pred = (y_probs >= self.threshold).astype(int)\n",
    "            return balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "        # We wrap them into scikit-learn scorers. \n",
    "        # needs_proba=True tells cross_validate to pass probabilities instead of hard labels.\n",
    "        custom_scorers = {\n",
    "            'f1': make_scorer(f1_at_threshold, needs_proba=True),\n",
    "            'balanced_accuracy': make_scorer(ba_at_threshold, needs_proba=True)\n",
    "        }\n",
    "\n",
    "        # Cross-Validation before final training\n",
    "        print(f\"[*] Performing 5-fold CV before final training (Threshold: {self.threshold:.3f})...\")\n",
    "        cv_results = cross_validate(\n",
    "            self.model, X_final, y_final, \n",
    "            cv=5, \n",
    "            scoring=custom_scorers, \n",
    "            n_jobs=1\n",
    "        )\n",
    "        \n",
    "        # Extract means and standard deviations\n",
    "        mean_f1 = cv_results['test_f1'].mean()\n",
    "        std_f1 = cv_results['test_f1'].std()\n",
    "        mean_ba = cv_results['test_balanced_accuracy'].mean()\n",
    "        std_ba = cv_results['test_balanced_accuracy'].std()\n",
    "        print(f\"[CV RESULTS] Threshold: {self.threshold:.3f}\")\n",
    "        print(f\" >> F1-Score:          {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "        print(f\" >> Balanced Accuracy: {mean_ba:.4f} ± {std_ba:.4f}\")\n",
    "\n",
    "        # Final fit on the entire dataset\n",
    "        print(\"[*] Training final model on the full provided dataset...\")\n",
    "        self.model.fit(X_final, y_final)\n",
    "        print(\"[✔] Model trained successfully!\")\n",
    "\n",
    "        # Confusion Matrix on the training data\n",
    "        print(f\"[*] Generating final training confusion matrix (Threshold: {self.threshold:.3f})...\")\n",
    "        # Predict probabilities on the training data\n",
    "        y_probs_final = self.model.predict_proba(X_final)[:, 1]\n",
    "        y_pred_final = (y_probs_final >= self.threshold).astype(int)\n",
    "        \n",
    "        # Compute and plot Confusion Matrix\n",
    "        cm = confusion_matrix(y_final, y_pred_final)\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Visitor\", \"Visitor\"])\n",
    "        disp.plot(cmap='Blues', ax=ax, values_format='d')\n",
    "        plt.title(f\"Final Training Confusion Matrix (Threshold: {self.threshold:.3f})\")\n",
    "        plt.grid(False)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f0efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Trainer with desired settings\n",
    "trainer = Train(data_manager, grayscale=False, multiscale=False, oversampling='random', ratio=0.1)\n",
    "\n",
    "# HoG Parameter Tuning\n",
    "# trainer.tune_hog_settings()\n",
    "# trainer.tune_multiscale_settings()\n",
    "\n",
    "# Hyperparameter Tuning Phases\n",
    "# for i in range(1, 5):\n",
    "#     trainer.tune_parameters(phase=i)\n",
    "\n",
    "# Threshold Tuning\n",
    "# trainer.tune_threshold()\n",
    "\n",
    "# Training the final model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775a5f87",
   "metadata": {},
   "source": [
    "## Parameters Tuning Results (tested on the whole dataset):\n",
    "\n",
    "### HOG parameters:\n",
    "{'pix': (8, 8), 'orient': 9, 'block': (1, 1)}\n",
    "- Result (Balanced Acc): 0.6047 ± 0.1083\n",
    "- Result (F1): 0.1702 ± 0.1545\n",
    "\n",
    "{'pix': (8, 8), 'orient': 6, 'block': (1, 1)}\n",
    "- Result (Balanced Acc): 0.5963 ± 0.1054\n",
    "- Result (F1): 0.1673 ± 0.1575\n",
    "\n",
    "{'pix': (12, 12), 'orient': 6, 'block': (1, 1)}\n",
    "- Result (Balanced Acc): 0.5860 ± 0.1125\n",
    "- Result (F1): 0.1191 ± 0.1013\n",
    "\n",
    "{'pix': (12, 12), 'orient': 9, 'block': (1, 1)}\n",
    "- Result (Balanced Acc): 0.6374 ± 0.1314\n",
    "- Result (F1): 0.1306 ± 0.0949\n",
    "\n",
    "Testing different values for pix, orient and block allowed us to determine the best combination. We did not go too low in pix or too high values to keep a model efficient (decreasing pix, increasing orient or increasing block make the features vector bigger, therefore making the training longer). We notice a large standard deviation, due to the 3-fold split being severe and the hyperparameters of our XGBoost not yet being optimized. We prioritize F1-Score over balanced accuracy, and therefore selection pix=(8, 8), orient=9 and block=(1, 1). \n",
    "\n",
    "### XGBoost Phase 1:\n",
    "\n",
    "\n",
    "We later changed scale_pos_weight to experiment with different hyper parameters and with the following rule: when there is no False Positive (the model predicting 1 when it's 0), we can increase scale_pos_weigth. If we start to get False Positive (or already have too much), decreasing it will establish better scores.\n",
    "\n",
    "We noted that if you put transform_sqrt to true in the HOG, the model needs a higher value (about 35, which is the ratio class 0 over class 1) for scale_pos_weight than when using transform_sqrt=False. transform_sqrt=False is more promising, can detect more insects, but quickly turn aggressive into making False Positive.\n",
    "\n",
    "### XGBoost Phase 2:\n",
    "\n",
    "\n",
    "### XGBoost Phase 3:\n",
    "\n",
    "\n",
    "### XGBoost Phase 4:\n",
    "\n",
    "\n",
    "### Oversampling methods\n",
    "\n",
    "For oversampling, we tried to resample the minority class with two methods to different proportions (10%, 15%, 20%, 30, 50%), by adjusting scale_pos_weight accordingly (for instance, if scale_pos_weight=55 when class 1 is 2.71% of the dataset, it becomes 15 with 10%, 8 with 20%, 5 for 30% and 3 for 50% etc., to be adjusted after observations).\n",
    "\n",
    "After testing different rebalancing values and adjusting scale_pos_weight, SMOTE constantly decreased (by a lot) our performance, confirming what we thought about SMOTE being inefficient here because of the classes not being well separated, so the oversampling creates insects that are not real and confuse the model.\n",
    "\n",
    "Random Oversampler showed great results and some improvements. With ratio=0.1 and scale_pos_weight=5 (max_delta_step=0), we peaked in balanced accuracy and F1-Score for 10% of the dataset, meaning that giving a bit more examples to the model while making it even more aggressive on the class 1 is a good strategy. Other resampling ratios didn't show better results (because of the few examples we have, too high ratios would duplicate too many times the same example to add good informations).\n",
    "\n",
    "### Detecting More and Minimizing False Alarms\n",
    "\n",
    "We tried to detect more insects by forcing some scale_pos_weigth, but noticed that we reached a cap where going up one more True Positive cost us a lot of False Positive, which was bad. We decided to introduce in our model the parameter max_delta_step=1 to constrain this, achieving a little rise in True Positive without a great cost in False Positive. The image below shows how scale_pos_weight reflects on the F1-Score. Too low and the model will just predict no insect for all examples, too high and it will predict too much insects (raising False Positive). The sweet spot is in between, where it predicts insects but don't hallucinate about seeing some insects when there's nothing.\n",
    "\n",
    "![scale_pos_weight_optimization.png](scale_pos_weight_optimization.png)\n",
    "\n",
    "### Final results\n",
    "\n",
    "In training with 10% of the dataset, the crossval score peaked at:\n",
    "\n",
    "Balanced Accuracy = 0.9474 \n",
    "\n",
    "F1 Score = 0.7692\n",
    "\n",
    "In training with 100% of the dataset, the crossval score peaked at:\n",
    "\n",
    "Balanced Accuracy =\n",
    "\n",
    "F1 Score = \n",
    "\n",
    "See hyperparameters below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52775bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter on 10% of the dataset:\n",
    "multiscale_10 = False\n",
    "grayscale_10 = False\n",
    "oversampling_10, ratio_10 = 'random', 0.1\n",
    "threshold_10 = 0.5\n",
    "\n",
    "model_10 = XGBClassifier( \n",
    "    n_estimators=250,  \n",
    "    max_depth=5,  \n",
    "    learning_rate=0.03, \n",
    "    subsample=0.8,      \n",
    "    colsample_bytree=0.8,  \n",
    "    scale_pos_weight=10,\n",
    "    min_child_weight=5,\n",
    "    max_delta_step=1,\n",
    "    gamma=0.5,  \n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    tree_method='hist',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    enable_categorical=False,\n",
    ")\n",
    "\n",
    "hog_10 = hog(any, orientations=12, pixels_per_cell=(16, 16), cells_per_block=(1, 1), transform_sqrt=False, channel_axis=-1)\n",
    "\n",
    "# Hyperparameters on 100% of the dataset:\n",
    "multiscale_100 = False\n",
    "grayscale_100 = False\n",
    "oversampling_100, ratio_100 = -1, -1\n",
    "threshold_100 = -1\n",
    "\n",
    "model_100 = XGBClassifier()\n",
    "\n",
    "hog_100 = hog(any, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(1, 1), transform_sqrt=False, channel_axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e797f7",
   "metadata": {},
   "source": [
    "# 4 - Scoring\n",
    "\n",
    "This section evaluates the trained model on unseen data using the X_test set from the data_manager. Testing on separate data is essential to verify the model's generalization capabilities and check for overfitting.\n",
    "\n",
    "## Methodology:\n",
    "Feature Extraction: Each test image is processed through the HOG algorithm using the trainer's optimized parameters to convert visual structures into a 1D feature vector compatible with the model.\n",
    "\n",
    "Metric Selection: Standard accuracy is misleading due to the high class imbalance (~2.7% visitors). We use the following metrics instead:\n",
    "\n",
    "Balanced Accuracy: Calculates the average recall for each class, giving equal importance to both majority and minority classes.\n",
    "\n",
    "F1-Score: The harmonic mean of Precision and Recall, providing a balanced view of the model's performance specifically on the \"Visitor\" class. NOTE: This is the main metric of the challenge, the one you will be ranked on.\n",
    "\n",
    "Confusion Matrix: A visual tool to identify the nature of errors, such as False Positives (misidentifying a flower as having an insect) or False Negatives (missing an actual insect).\n",
    "\n",
    "In an imbalanced dataset, Balanced Accuracy prevents the model from appearing successful by simply guessing the majority class, as it calculates the average performance across both classes independently. Meanwhile, the F1-Score provides a single measure of reliability by balancing the trade-off between avoiding false alarms (Precision) and ensuring no actual visitors are missed (Recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a01112",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Score:\n",
    "    def __init__(self, data_manager, trainer):\n",
    "        \"\"\"\n",
    "        Initializes the scoring class and extracts features using the trainer's configuration.\n",
    "        \"\"\"\n",
    "        self.data = data_manager\n",
    "        self.trainer = trainer\n",
    "        self.results = {}\n",
    "        self.cm = None\n",
    "        self.X_test_features = None\n",
    "\n",
    "        if trainer.multiscale:\n",
    "            self.X_test_features = self.extract_hog_test_multiscale()\n",
    "        else:\n",
    "            self.X_test_features = self.extract_hog_test()\n",
    "\n",
    "    # --- Parallel Helpers ---\n",
    "    def _process_single(self, img):\n",
    "        \"\"\"Helper for parallel single-scale extraction on test set.\"\"\"\n",
    "        img_proc = rgb2gray(img) if self.trainer.grayscale else img\n",
    "        c_axis = None if self.trainer.grayscale else -1\n",
    "        return hog(img_proc, \n",
    "                   orientations=self.trainer.best_h_orient, \n",
    "                   pixels_per_cell=self.trainer.best_h_pix, \n",
    "                   cells_per_block=self.trainer.best_h_block, \n",
    "                   transform_sqrt=self.trainer.best_h_transform_sqrt, \n",
    "                   channel_axis=c_axis)\n",
    "\n",
    "    def _process_multi(self, img):\n",
    "        \"\"\"Helper for parallel multi-scale extraction on test set.\"\"\"\n",
    "        img_proc = rgb2gray(img) if self.trainer.grayscale else img\n",
    "        c_axis = None if self.trainer.grayscale else -1\n",
    "\n",
    "        # Synchronize multi-scale configs from trainer if they exist\n",
    "        s1 = getattr(self.trainer, 's1_config', (12, (16, 16), (1, 1), False))\n",
    "        s2 = getattr(self.trainer, 's2_config', (9, (8, 8), (1, 1), False))\n",
    "\n",
    "        h1 = hog(img_proc, orientations=s1[0], pixels_per_cell=s1[1],\n",
    "                 cells_per_block=s1[2], transform_sqrt=s1[3], channel_axis=c_axis)\n",
    "        \n",
    "        h2 = hog(img_proc, orientations=s2[0], pixels_per_cell=s2[1],\n",
    "                 cells_per_block=s2[2], transform_sqrt=s2[3], channel_axis=c_axis)\n",
    "        \n",
    "        return np.concatenate([h1, h2])\n",
    "\n",
    "    # --- Extraction Methods ---\n",
    "    def extract_hog_test(self):\n",
    "        \"\"\"\n",
    "        Extracts HOG features from the test set using parallel processing.\n",
    "        \"\"\"\n",
    "        print(f\"[*] Extracting HOG features from {len(self.data.X_test)} test images (Parallel)...\")\n",
    "        features = Parallel(n_jobs=-1)(\n",
    "            delayed(self._process_single)(img) for img in tqdm(self.data.X_test, desc=\"Test HOG\")\n",
    "        )\n",
    "        return np.array(features)\n",
    "\n",
    "    def extract_hog_test_multiscale(self):\n",
    "        \"\"\"\n",
    "        Extracts Multi-scale HOG features from the test set using parallel processing.\n",
    "        \"\"\"\n",
    "        print(f\"[*] Extracting Multi-scale HOG from {len(self.data.X_test)} test images (Parallel)...\")\n",
    "        features = Parallel(n_jobs=-1)(\n",
    "            delayed(self._process_multi)(img) for img in tqdm(self.data.X_test, desc=\"Test Multi-HOG\")\n",
    "        )\n",
    "        return np.array(features)\n",
    "\n",
    "    def compute_score(self):\n",
    "        \"\"\"\n",
    "        Computes predictions and scores using a custom probability threshold.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            check_is_fitted(self.trainer.model)\n",
    "        except NotFittedError:\n",
    "            print(\"[!] Trainer model is not fitted. Please train the model before scoring.\")\n",
    "            return None\n",
    "        \n",
    "        if self.X_test_features is None:\n",
    "            if self.trainer.multiscale:\n",
    "                self.X_test_features = self.extract_hog_test_multiscale()\n",
    "            else:\n",
    "                self.X_test_features = self.extract_hog_test()\n",
    "        \n",
    "        # Predicting with probabilities for threshold control\n",
    "        print(f\"[*] Predicting on test set with threshold {self.trainer.threshold}...\")\n",
    "        y_probs = self.trainer.model.predict_proba(self.X_test_features)[:, 1]\n",
    "        y_pred = (y_probs >= self.trainer.threshold).astype(int)\n",
    "        y_true = self.data.y_test\n",
    "        \n",
    "        # Confusion Matrix      \n",
    "        self.cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        # Metrics Calculation\n",
    "        self.results['Threshold'] = self.trainer.threshold\n",
    "        self.results['Balanced Accuracy'] = balanced_accuracy_score(y_true, y_pred)\n",
    "        self.results['F1 Score'] = f1_score(y_true, y_pred, pos_label=1)\n",
    "        \n",
    "        self._display_results()\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "    def _display_results(self):\n",
    "        \"\"\"Displays the metrics table and the confusion matrix.\"\"\"\n",
    "        print(\"=\"*40)\n",
    "        print(f\"{'EVALUATION METRICS':^40}\")\n",
    "        print(\"=\"*40)\n",
    "        for metric, value in self.results.items():\n",
    "            print(f\"{metric:<20} : {value:.4f}\")\n",
    "        print(\"=\"*40)\n",
    "\n",
    "        print(\"\\n[*] Plotting Confusion Matrix...\")\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=self.cm, display_labels=[\"No Visitor\", \"Visitor\"])\n",
    "        disp.plot(cmap='Blues', ax=ax, values_format='d')\n",
    "        plt.title(f\"Confusion Matrix (Threshold: {self.results.get('Threshold', 0.5)})\")\n",
    "        plt.grid(False)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bcd23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = Score(data_manager, trainer)\n",
    "score.compute_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8565338c",
   "metadata": {},
   "source": [
    "## Final results\n",
    "\n",
    "### 10% of the dataset\n",
    "For 10% of the whole dataset, with the simple scale RGB HOG with oversampling (the model we found was the best during training), our balanced accuracy reached at 0.696 and our F1-score at 0.564. This shows a big overfitting on the train set (-0.251 in balanced accuracy and -0.205 in F1-score), which is typical of XGBoost and imbalanced datasets. Future improvements could be on the regularization to decrease overfitting.\n",
    "\n",
    "### 100% of the dataset \n",
    "For 100% of the whole dataset, with the simple scale RGB HOG with oversampling (the model we found was the best during training), our balanced accuracy reached at 0. and our F1-score at 0.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01138f4",
   "metadata": {},
   "source": [
    "# 4.5 Full Parameters Optimization (just as an example, do not run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c733eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Execution and Logging for Hyperparameter Tuning (do not use fully, it's a long one)\n",
    "# Was used to generate the final optimized model and log results (on 10% of data for speed)\n",
    "\n",
    "log_file = \"hog_optimization_results.txt\"\n",
    "with open(log_file, \"w\") as f:\n",
    "    f.write(\"=== HOG OPTIMIZATION LOG ===\\n\\n\")\n",
    "\n",
    "for i in range(0, 2): # 0 = Single-scale, 1 = Multi-scale\n",
    "    for j in [False, True]: # Grayscale options\n",
    "        trainer = Train(data_manager, grayscale=j, multiscale=bool(i))\n",
    "        \n",
    "        # Tuning HOG settings\n",
    "        if i == 0:\n",
    "            mode = \"Single-Scale\"\n",
    "            trainer.tune_hog_settings()\n",
    "        else:\n",
    "            mode = \"Multi-Scale\"\n",
    "            trainer.tune_multiscale_settings()\n",
    "            \n",
    "        # Tuning XGBoost phases\n",
    "        for p in range(1, 5):\n",
    "            trainer.tune_parameters(phase=p)\n",
    "\n",
    "        # Tuning threshold\n",
    "        trainer.tune_threshold()\n",
    "            \n",
    "        # Training\n",
    "        trainer.train(oversampling=None)\n",
    "\n",
    "        # Summary data\n",
    "        relevant_params = [\n",
    "            'n_estimators', 'max_depth', 'learning_rate', 'subsample', \n",
    "            'colsample_bytree', 'scale_pos_weight', 'min_child_weight', \n",
    "            'max_delta_step', 'gamma', 'reg_alpha', 'reg_lambda'\n",
    "        ]\n",
    "        all_params = trainer.model.get_params()\n",
    "        filtered_params = {k: all_params[k] for k in relevant_params if k in all_params}\n",
    "        \n",
    "        hog_info = (f\"Orient={trainer.best_h_orient}, Pix={trainer.best_h_pix}, Block={trainer.best_h_block}\" \n",
    "                    if not i else f\"S1={trainer.s1_config}, S2={trainer.s2_config}\")\n",
    "        \n",
    "        # Logging results\n",
    "        output = (\n",
    "            f\"\\n{'='*40}\\n\"\n",
    "            f\"[Summary] Mode: {mode} | Grayscale: {j}\\n\"\n",
    "            f\"HOG Settings: {hog_info}\\n\"\n",
    "            f\"Final Model Params: {filtered_params}\\n\"\n",
    "            f\"Optimized Threshold: {trainer.threshold}\\n\"\n",
    "        )\n",
    "        print(output)\n",
    "        \n",
    "        with open(log_file, \"a\") as f:\n",
    "            f.write(output)\n",
    "\n",
    "        # Scoring\n",
    "        score = Score(data_manager, trainer)\n",
    "        res = score.compute_score()\n",
    "            \n",
    "        score_line = (\n",
    "            f\"F1: {res['F1 Score']:.4f} | Balanced Acc: {res['Balanced Accuracy']:.4f}\\n\"\n",
    "            f\"{'-'*40}\\n\"\n",
    "        )\n",
    "        print(score_line)\n",
    "        with open(log_file, \"a\") as f:\n",
    "            f.write(score_line)\n",
    "                \n",
    "        # Cleanup\n",
    "        del trainer\n",
    "        del score\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede87bdd",
   "metadata": {},
   "source": [
    "# 5 - (Optional) Prepare submission for Codabench"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccf7cb8-cf09-4e12-8129-2a0bd06b147c",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "In this section you can prepare a zip of the trained model and the predictions to make your submission. You just have to execute the cell and a zip file will be created automatically, after training your model on the full training dataset and predicting on the hidden test set.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08d8459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "class Submission:\n",
    "    def __init__(self, submission_dir, zip_file_name):\n",
    "        self.submission_dir = submission_dir\n",
    "        self.zip_file_name = zip_file_name\n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(self.submission_dir, exist_ok=True)\n",
    "\n",
    "    def save_code(self, model):\n",
    "        \"\"\"\n",
    "        Saves the trained model object to the submission directory.\n",
    "        \"\"\"\n",
    "        model_path = os.path.join(self.submission_dir, \"model.joblib\")\n",
    "        joblib.dump(model, model_path)\n",
    "        print(f\"Model saved at: {model_path}\")\n",
    "\n",
    "    def save_result(self, predictions):\n",
    "        \"\"\"\n",
    "        Saves the prediction array as a CSV file.\n",
    "        \"\"\"\n",
    "        result_path = os.path.join(self.submission_dir, \"results.csv\")\n",
    "        # Convert to DataFrame for a clean CSV\n",
    "        df = pd.DataFrame(predictions, columns=[\"prediction\"])\n",
    "        df.to_csv(result_path, index=False)\n",
    "        print(f\"Predictions saved at: {result_path}\")\n",
    "        \n",
    "    def zip_submission(self):\n",
    "        # Path to ZIP\n",
    "        zip_path = os.path.join(self.submission_dir, self.zip_file_name)\n",
    "\n",
    "        # Create ZIP containing the submission directory files\n",
    "        with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "            for filename in os.listdir(self.submission_dir):\n",
    "                file_path = os.path.join(self.submission_dir, filename)\n",
    "\n",
    "                # Skip the zip file itself and hidden files\n",
    "                if file_path == zip_path or filename.startswith('.'):\n",
    "                    continue\n",
    "\n",
    "                zf.write(file_path, arcname=filename)\n",
    "        print(f\"Submission ZIP saved at: {zip_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2700348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Submission Generation on Hidden Set\n",
    "# Use the full 30k training images to train the final model\n",
    "trainer.data.X_train = data_manager.X_train_full\n",
    "trainer.y_train = data_manager.y_train_full\n",
    "trainer.X_train_features = None # Force re-extraction of features\n",
    "trainer.train()\n",
    "\n",
    "# Preparation for final prediction\n",
    "print(f\"[*] Preparing final prediction...\")\n",
    "\n",
    "# Instantiate Score (this will automatically trigger HOG extraction via __init__)\n",
    "data_manager.X_test = data_manager.X_hidden\n",
    "scorer_hidden = Score(data_manager, trainer)\n",
    "\n",
    "# Prediction on hidden set\n",
    "print(f\"[*] Predicting on hidden set with threshold {trainer.threshold:.3f}...\")\n",
    "X_hidden_features = scorer_hidden.X_test_features\n",
    "\n",
    "y_probs_hidden = trainer.model.predict_proba(X_hidden_features)[:, 1]\n",
    "y_pred_hidden = (y_probs_hidden >= trainer.threshold).astype(int)\n",
    "\n",
    "# Export submission\n",
    "zip_file_name = f\"Submission_{datetime.datetime.now().strftime('%y-%m-%d-%H-%M')}.zip\"\n",
    "submission = Submission(submission_dir=\"./submission\", zip_file_name=zip_file_name)\n",
    "\n",
    "submission.save_code(trainer.model)\n",
    "submission.save_result(y_pred_hidden)\n",
    "submission.zip_submission()\n",
    "\n",
    "print(f\"\\n[OK] Submission generated with {len(y_pred_hidden)} predictions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
